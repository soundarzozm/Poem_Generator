{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poem_generator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLj7sXHsx01tftfjmLAbO0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jObsfyqYqQl6",
        "colab_type": "text"
      },
      "source": [
        "<h1>Poem Generator using RNN</h1>\n",
        "\n",
        "Welcome to the notebook!<br>\n",
        "We'll be generating poems by taking the seed text, the style of the poem (Shakespearian Sonnets or Irish lyrics), and the number of words to be predicted as an input from the user.<br>\n",
        "<br>\n",
        "Let's get started by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MteFuLFlvSfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR1ubRppqe22",
        "colab_type": "text"
      },
      "source": [
        "Let's download both the datasets (Shakespearian Sonnets and Irish lyrics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhcaKuISvkJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8d7caf0f-10fc-44c4-bb34-a74a4236783b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
        "    -O /tmp/irish-lyrics-eof.txt\n",
        "data_irish = open('/tmp/irish-lyrics-eof.txt').read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-05 15:19:56--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 74.125.31.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68970 (67K) [text/plain]\n",
            "Saving to: ‘/tmp/irish-lyrics-eof.txt’\n",
            "\n",
            "\r          /tmp/iris   0%[                    ]       0  --.-KB/s               \r/tmp/irish-lyrics-e 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-09-05 15:19:57 (70.2 MB/s) - ‘/tmp/irish-lyrics-eof.txt’ saved [68970/68970]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDOet714vquk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "08b55be2-865d-4094-be64-1be2577b9f8c"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data_shakespeare = open('/tmp/sonnets.txt').read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-05 15:19:57--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-09-05 15:19:57 (55.6 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XQCOhdqq7EN",
        "colab_type": "text"
      },
      "source": [
        "Here we focus on two important steps we take regarding **feature engineering**:\n",
        "\n",
        "\n",
        "1.   Tokenization\n",
        "2.   Padding\n",
        "\n",
        "###Tokenization\n",
        "The process involves building a word index dictionary which tokenizes each word in the training set i.e. we index every unique word in the training dataset.<br>\n",
        "<br>\n",
        "###Padding\n",
        "Every sentence in the dataset would not have the same number of words obviously. Now this is a problem because neural networks expect a fixed input size.<br>\n",
        "We overcome this problem by keeping a fixed input size of 150 and pad the shorter sentences such that they possess the same shape. Also, we have set the truncation type to *post* which means, when it comes to sentences longer than 150 words, only the first 150 words would be taken into account and the rest of the words would simply be trimmed off.<br>\n",
        "<br>\n",
        "Let's perform this for both Shakesperian Sonnets and Irish lyrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUfYsF2vsr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_irish = Tokenizer()\n",
        "\n",
        "corpus_irish = data_irish.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer_irish.fit_on_texts(corpus_irish)\n",
        "total_words_irish = len(tokenizer_irish.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences_irish = []\n",
        "for line in corpus_irish:\n",
        "\ttoken_list = tokenizer_irish.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences_irish.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len_irish = max([len(x) for x in input_sequences_irish])\n",
        "input_sequences_irish = np.array(pad_sequences(input_sequences_irish, maxlen=max_sequence_len_irish, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors_irish, label_irish = input_sequences_irish[:,:-1],input_sequences_irish[:,-1]\n",
        "\n",
        "label_irish = ku.to_categorical(label_irish, num_classes=total_words_irish)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNedOQezvxsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_shakespeare = Tokenizer()\n",
        "\n",
        "corpus_shakespeare  = data_shakespeare.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer_shakespeare.fit_on_texts(corpus_shakespeare)\n",
        "total_words_shakespeare = len(tokenizer_shakespeare.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences_shakespeare = []\n",
        "for line in corpus_shakespeare:\n",
        "\ttoken_list = tokenizer_shakespeare.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences_shakespeare.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len_shakespeare = max([len(x) for x in input_sequences_shakespeare])\n",
        "input_sequences_shakespeare = np.array(pad_sequences(input_sequences_shakespeare, maxlen=max_sequence_len_shakespeare, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors_shakespeare, label_shakespeare = input_sequences_shakespeare[:,:-1],input_sequences_shakespeare[:,-1]\n",
        "\n",
        "label_shakespeare = ku.to_categorical(label_shakespeare, num_classes=total_words_shakespeare)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMF0ApsCrHE8",
        "colab_type": "text"
      },
      "source": [
        "Now, let us import the models that we had trained and saved in the other notebooks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plJQVHUv1lF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_irish = tensorflow.keras.models.load_model('irish_model.h5')\n",
        "model_shakespeare = tensorflow.keras.models.load_model('shakespeare_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF6tG2CgrPZr",
        "colab_type": "text"
      },
      "source": [
        "Here we define a function that uses the imported trained models to generate the poems.<br>\n",
        "Note the parameters specified as the function's input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Zv5DKowOPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(seed_text, next_words, model_name):\n",
        "  if model_name=='irish':\n",
        "    for _ in range(next_words):\n",
        "\t    token_list = tokenizer_irish.texts_to_sequences([seed_text])[0]\n",
        "\t    token_list = pad_sequences([token_list], maxlen=max_sequence_len_irish-1, padding='pre')\n",
        "\t    predicted = model_irish.predict_classes(token_list, verbose=0)\n",
        "\t    output_word = \"\"\n",
        "\t    for word, index in tokenizer_irish.word_index.items():\n",
        "\t\t    if index == predicted:\n",
        "\t\t\t    output_word = word\n",
        "\t\t\t    break\n",
        "\t    seed_text += \" \" + output_word\n",
        "    return(seed_text)\n",
        "  elif model_name=='shakespeare':\n",
        "    for _ in range(next_words):\n",
        "\t    token_list = tokenizer_shakespeare.texts_to_sequences([seed_text])[0]\n",
        "\t    token_list = pad_sequences([token_list], maxlen=max_sequence_len_shakespeare-1, padding='pre')\n",
        "\t    predicted = model_shakespeare.predict_classes(token_list, verbose=0)\n",
        "\t    output_word = \"\"\n",
        "\t    for word, index in tokenizer_shakespeare.word_index.items():\n",
        "\t\t    if index == predicted:\n",
        "\t\t\t    output_word = word\n",
        "\t\t\t    break\n",
        "\t    seed_text += \" \" + output_word\n",
        "    return(seed_text)\n",
        "  else:\n",
        "    print('Invalid model name!')\n",
        "    return      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0vv9PAkre37",
        "colab_type": "text"
      },
      "source": [
        "<h2>Let's test our final function!</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY3PMzXxwpRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"shubham my love\"\n",
        "next_words = 20\n",
        "model_name = 'irish'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfIfL9bnwtOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "348a27ea-403f-4f2c-a8f6-328399229243"
      },
      "source": [
        "generate(seed_text, next_words, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'shubham my love is fairer than any day and tried to take them from me go word by corporal casey i love so'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk3jnoqxxMOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"Jeet ate pizza today\"\n",
        "next_words = 20\n",
        "model_name = 'shakespeare'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn3XbBFSxNxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89aac445-c9ce-42fe-d01d-a04fd22ef447"
      },
      "source": [
        "generate(seed_text, next_words, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Jeet ate pizza today no praise wilt but the expense by those old erred some messengers worthier thee hast gone ' ' ' '\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-al5wNfyroOO",
        "colab_type": "text"
      },
      "source": [
        "<h2>Perfect!</h2>\n",
        "\n",
        "*Conclusion:* We have successfully implemented the function to generate poems taking:\n",
        "1.    Seed text\n",
        "2.    No. of words to be generated\n",
        "3.    Style of the poem\n",
        "\n",
        "to generate appropriate output using the trained RNN models from the other notebooks."
      ]
    }
  ]
}